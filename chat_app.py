import streamlit as st
from google import genai
import os # ‡§Ö‡§ó‡§∞ ‡§ú‡§º‡§∞‡•Ç‡§∞‡•Ä ‡§π‡•ã ‡§§‡•ã

st.title("‡§Æ‡•á‡§∞‡§æ Buddy AI ‡§ö‡•à‡§ü‡§¨‡•â‡§ü üí¨")

# 1. API Key ‡§î‡§∞ ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•Ä ‡§∂‡•Å‡§∞‡•Å‡§Ü‡§§
if "GEMINI_API_KEY" not in st.secrets:
    st.error("‡§ï‡•É‡§™‡§Ø‡§æ Streamlit Secrets ‡§Æ‡•á‡§Ç GEMINI_API_KEY ‡§∏‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç‡•§")
    # ‡§Ö‡§ó‡§∞ Key ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à, ‡§§‡•ã ‡§ö‡•à‡§ü ‡§ï‡•ã ‡§®‡§ø‡§∑‡•ç‡§ï‡•ç‡§∞‡§ø‡§Ø ‡§∞‡§ñ‡•á‡§Ç
    st.session_state.chat = None 
    st.session_state.messages = [{"role": "assistant", "content": "‡§ö‡•à‡§ü ‡§∂‡•Å‡§∞‡•Ç ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è API Key ‡§∏‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç‡•§"}]
    
else:
    # API Key ‡§ï‡•ã ‡§∏‡•Ä‡§ß‡•á GenerativeModel ‡§Æ‡•á‡§Ç ‡§™‡§æ‡§∏ ‡§ï‡§∞‡•á‡§Ç (configure() ‡§ï‡•ã ‡§õ‡•ã‡§°‡§º ‡§¶‡•á‡§Ç)
    API_KEY = st.secrets["GEMINI_API_KEY"]
    model_name = "gemini-2.5-flash"
    
    if "chat" not in st.session_state:
        try:
            # Model ‡§ï‡•ã API Key ‡§ï‡•á ‡§∏‡§æ‡§• initialize ‡§ï‡§∞‡•á‡§Ç
            model = genai.GenerativeModel(model_name, api_key=API_KEY)
            st.session_state.chat = model.start_chat(history=[])
            st.session_state.messages = []
        except Exception as e:
            st.error(f"‡§Æ‡•â‡§°‡§≤ ‡§∂‡•Å‡§∞‡•Ç ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ‡•§ ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™‡§ï‡•Ä API Key ‡§∏‡§π‡•Ä ‡§π‡•à? Error: {e}")
            st.session_state.chat = None


# 2. ‡§™‡§ø‡§õ‡§≤‡•Ä ‡§ö‡•à‡§ü ‡§¶‡§ø‡§ñ‡§æ‡§è‡§Å
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 3. ‡§Ø‡•Ç‡§ú‡§º‡§∞ ‡§á‡§®‡§™‡•Å‡§ü ‡§≤‡•á‡§Ç ‡§î‡§∞ AI ‡§∏‡•á ‡§ú‡§µ‡§æ‡§¨ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡•á‡§Ç
if prompt := st.chat_input("‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡•à‡§∏‡•á ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å?"):
    if st.session_state.chat is None:
        st.error("‡§ö‡•à‡§ü API Key ‡§ï‡•Ä ‡§ï‡§Æ‡•Ä ‡§ï‡•á ‡§ï‡§æ‡§∞‡§£ ‡§®‡§ø‡§∑‡•ç‡§ï‡•ç‡§∞‡§ø‡§Ø ‡§π‡•à‡•§")
    
    else:
        # ‡§Ø‡•Ç‡§ú‡§º‡§∞ ‡§ï‡§æ ‡§Æ‡•à‡§∏‡•á‡§ú ‡§¶‡§ø‡§ñ‡§æ‡§è‡§Å
        with st.chat_message("user"):
            st.markdown(prompt)

        # ‡§Ø‡•Ç‡§ú‡§º‡§∞ ‡§ï‡•á ‡§Æ‡•à‡§∏‡•á‡§ú ‡§ï‡•ã ‡§ö‡•à‡§ü ‡§π‡§ø‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä ‡§Æ‡•á‡§Ç ‡§∏‡•á‡§µ ‡§ï‡§∞‡•á‡§Ç
        st.session_state.messages.append({"role": "user", "content": prompt})

        # AI ‡§ï‡§æ ‡§ú‡§µ‡§æ‡§¨ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡•á‡§Ç 
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            
            try:
                # Gemini API ‡§∏‡•á ‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Æ‡§ø‡§Ç‡§ó ‡§ú‡§µ‡§æ‡§¨ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡•á‡§Ç
                response_stream = st.session_state.chat.send_message_streaming(prompt)
                
                for chunk in response_stream:
                    if chunk.text:
                        full_response += chunk.text
                        message_placeholder.markdown(full_response + "‚ñå") 
                
                # ‡§™‡•Ç‡§∞‡§æ ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡§ø‡§ñ‡§æ‡§®‡•á ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§ü‡§æ‡§á‡§™‡§ø‡§Ç‡§ó ‡§á‡§´‡§º‡•á‡§ï‡•ç‡§ü ‡§π‡§ü‡§æ ‡§¶‡•á‡§Ç
                message_placeholder.markdown(full_response)
                
            except Exception as e:
                full_response = f"‡§Æ‡§æ‡§´‡§º ‡§ï‡§∞‡§®‡§æ, ‡§ï‡§®‡•á‡§ï‡•ç‡§∂‡§® ‡§Æ‡•á‡§Ç ‡§ï‡•ã‡§à ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•à‡•§ Error: {e}"
                message_placeholder.markdown(full_response)

        # AI ‡§ï‡•á ‡§ú‡§µ‡§æ‡§¨ ‡§ï‡•ã ‡§ö‡•à‡§ü ‡§π‡§ø‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä ‡§Æ‡•á‡§Ç ‡§∏‡•á‡§µ ‡§ï‡§∞‡•á‡§Ç
        st.session_state.messages.append({"role": "assistant", "content": full_response})
